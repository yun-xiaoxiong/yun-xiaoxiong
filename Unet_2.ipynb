{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0d3USglM5yE210JTC+XE5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yun-xiaoxiong/yun-xiaoxiong/blob/main/Unet_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvPtCSyFkEVv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=1e-6\n",
        "batch_size=1\n",
        "epoch=100\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "TJi6r_AwkKSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unit(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out,kernel_size=3,stride=1,padding=1):\n",
        "        super(Unit,self).__init__()\n",
        "        self.an_unit=nn.Sequential(                         \n",
        "            nn.Conv2d(ch_in,ch_out,kernel_size=kernel_size,stride=stride,padding=padding),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out,ch_out,kernel_size=kernel_size,stride=stride,padding=padding),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.an_unit(x)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Unet,self).__init__()\n",
        "        self.pool=nn.MaxPool2d(2,stride=2)\n",
        "        self.cr1=Unit(1,64)\n",
        "        self.cr2=Unit(64,128)\n",
        "        self.cr3=Unit(128,256)\n",
        "        self.cr4=Unit(256,512)\n",
        "        self.cr5=Unit(512,1024)\n",
        "        \n",
        "        self.up1=Unit(1024,512)\n",
        "        self.up2=Unit(512,256)\n",
        "        self.up3=Unit(256,128)\n",
        "        self.up4=Unit(128,64)\n",
        "        \n",
        "        self.conv=nn.Sequential(\n",
        "            nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,2,kernel_size=1,stride=1,padding=0)\n",
        "        )\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x1=self.cr1(x)\n",
        "        x2=self.cr2(self.pool(x1))\n",
        "        x3=self.cr3(self.pool(x2))\n",
        "        x4=self.cr4(self.pool(x3))\n",
        "        x5=self.cr5(self.pool(x4))\n",
        "        x5_up=self.up1(nn.functional.interpolate(x5,64))\n",
        "        #print(x4.shape)\n",
        "        #print(x5_up.shape)\n",
        "        x6=self.up1(torch.cat([x4,x5_up],1))\n",
        "        x6_up=self.up2(nn.functional.interpolate(x6,128))\n",
        "        x7=self.up2(torch.cat([x3,x6_up],1))\n",
        "        x7_up=self.up3(nn.functional.interpolate(x7,256))\n",
        "        x8=self.up3(torch.cat([x2,x7_up],1))\n",
        "        x8_up=self.up4(nn.functional.interpolate(x8,512))\n",
        "        x9=self.up4(torch.cat([x1,x8_up],1))\n",
        "        x10=self.conv(x9)\n",
        "        return x10"
      ],
      "metadata": {
        "id": "4nMLMUcmkisO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(2,512,512,requires_grad=True)\n",
        "y=torch.ones(2,512,512,requires_grad=True)\n",
        "model=Unet()\n",
        "model=model.cuda()\n",
        "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "  model.train()\n",
        "  for ep in range(epoch):\n",
        "      feature=x\n",
        "      label=y\n",
        "      a=[]\n",
        "      feature=feature.cuda()\n",
        "      label=label.cuda()\n",
        "      out=model(feature.unsqueeze(1))\n",
        "      pred=out.transpose(1,2).transpose(2,3).contiguous().view(-1,2)\n",
        "      \n",
        "      true=label.view(-1).long()\n",
        "      loss=loss_fn(pred,true)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      a.append(loss.item())\n",
        "      print(\"epoch:\",ep+1,\"  loss: \",np.mean(a))\n",
        "      test()"
      ],
      "metadata": {
        "id": "DuwTfnipknYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "8122481b-484b-4799-83db-ce6555d16291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5b7accc49cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    feature=x\n",
        "    label=y\n",
        "    model.eval()\n",
        "    feature=feature.to(device)\n",
        "    label=label.to(device)\n",
        "    out=model(feature.unsqueeze(1))\n",
        "    pred=nn.functional.softmax(out.cpu(),dim=1) # torch.Size([4, 2, 512, 512])- > [4,2,512,512]\n",
        "    label=label.cpu()\n",
        "    with torch.no_grad():\n",
        "      pred=pred[:,1,:,:]\n",
        "      torch.squeeze(pred,1)\n",
        "      pred[pred >= 0.5] = 1\n",
        "      pred[pred < 0.5] = 0\n",
        "      # pred = np.array(pred.data.cpu()[0])[0]\n",
        "      jiao=(label*pred).sum().item()\n",
        "      bing=(label+pred).clamp(max=1).sum().item()\n",
        "      IOU=jiao/bing\n",
        "      print(\"交集：\",jiao,\"  并集:\",bing)\n",
        "    accuracy=IOU*100\n",
        "    print(\"IOU accuracy: \",accuracy,\"% \")\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    return IOU"
      ],
      "metadata": {
        "id": "GfULEvc3liUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "Wh6BqozFm-m3",
        "outputId": "98a45130-1c65-41bf-82dd-6b9d59a4434e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-3f812c8db5ca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    }
  ]
}